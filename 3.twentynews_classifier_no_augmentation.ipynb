{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch, Sklearn imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 0.4.1\n",
      "AllenNLP: 0.8.1\n"
     ]
    }
   ],
   "source": [
    "## AllenNLP\n",
    "import allennlp\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from allennlp.modules.token_embedders import BertEmbedder\n",
    "\n",
    "print(\"PyTorch: {}\".format(torch.__version__))\n",
    "print(\"AllenNLP: {}\".format(allennlp.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/06/2019 17:11:16 - INFO - gensim.summarization.textcleaner -   'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## NLP libs\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "download('stopwords')\n",
    "\n",
    "## Sklearn imports\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "## General libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import os, re, sys, json, requests, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization function based on Spacy Library\n",
    "def lemmatizer_spacy(text):        \n",
    "    sent = []\n",
    "    doc = spacy_en(text)\n",
    "    for word in doc:\n",
    "        if word.lemma_ == \"-PRON-\":\n",
    "            sent.append(word.text)\n",
    "        else:\n",
    "            sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=True, do_stem=False, do_lema = False):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing E-mails  \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    text = re.sub(r'\\S*@\\S*\\s?', r' ', text)\n",
    "    \n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Removing Newline\n",
    "    text = text.rstrip()\n",
    "    # Removing all the stopwords\n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Stemming\n",
    "    if (do_stem==True):\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    \n",
    "    # Lemmatization\n",
    "    if (do_lema==True):\n",
    "        text = do_lemmatization(text)   \n",
    "        \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: twillis@ec.ecn.purdue.edu (Thomas E Willis)\\nSubject: PB questions...\\nOrganization: Purdue University Engineering Computer Network\\nDistribution: usa\\nLines: 36\\n\\nwell folks, my mac plus finally gave up the ghost this weekend after\\nstarting life as a 512k way back in 1985.  sooo, i\\'m in the market for a\\nnew machine a bit sooner than i intended to be...\\n\\ni\\'m looking into picking up a powerbook 160 or maybe 180 and have a bunch\\nof questions that (hopefully) somebody can answer:\\n\\n* does anybody know any dirt on when the next round of powerbook\\nintroductions are expected?  i\\'d heard the 185c was supposed to make an\\nappearence \"this summer\" but haven\\'t heard anymore on it - and since i\\ndon\\'t have access to macleak, i was wondering if anybody out there had\\nmore info...\\n\\n* has anybody heard rumors about price drops to the powerbook line like the\\nones the duo\\'s just went through recently?\\n\\n* what\\'s the impression of the display on the 180?  i could probably swing\\na 180 if i got the 80Mb disk rather than the 120, but i don\\'t really have\\na feel for how much \"better\" the display is (yea, it looks great in the\\nstore, but is that all \"wow\" or is it really that good?).  could i solicit\\nsome opinions of people who use the 160 and 180 day-to-day on if its worth\\ntaking the disk size and money hit to get the active display?  (i realize\\nthis is a real subjective question, but i\\'ve only played around with the\\nmachines in a computer store breifly and figured the opinions of somebody\\nwho actually uses the machine daily might prove helpful).\\n\\n* how well does hellcats perform?  ;)\\n\\nthanks a bunch in advance for any info - if you could email, i\\'ll post a\\nsummary (news reading time is at a premium with finals just around the\\ncorner... :( )\\n--\\nTom Willis  \\\\  twillis@ecn.purdue.edu    \\\\    Purdue Electrical Engineering\\n---------------------------------------------------------------------------\\n\"Convictions are more dangerous enemies of truth than lies.\"  - F. W.\\nNietzsche\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 2\n",
    "x=newsgroups_train.data[idx]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from thomas e willis subject pb questions organization purdue university engineering computer network distribution usa lines 36 well folks mac plus finally gave ghost weekend starting life 512k way back 1985 sooo i m market new machine bit sooner intended be i m looking picking powerbook 160 maybe 180 bunch questions hopefully somebody answer anybody know dirt next round powerbook introductions expected i d heard 185c supposed make appearence this summer heard anymore since access macleak wondering anybody info anybody heard rumors price drops powerbook line like ones duo s went recently what s impression display 180 could probably swing 180 got 80mb disk rather 120 really feel much better display yea looks great store wow really good could solicit opinions people use 160 180 day to day worth taking disk size money hit get active display i realize real subjective question i ve played around machines computer store breifly figured opinions somebody actually uses machine daily might prove helpful well hellcats perform thanks bunch advance info could email i ll post summary news reading time premium finals around corner tom willis purdue electrical engineering convictions dangerous enemies truth lies f w nietzsche'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformText(x, do_stop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame({'phrase': newsgroups_train.data, 'intent': newsgroups_train.target})\n",
    "test_dataset = pd.DataFrame({'phrase': newsgroups_test.data, 'intent': newsgroups_test.target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>13</td>\n",
       "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>4</td>\n",
       "      <td>From: ebodin@pearl.tufts.edu\\nSubject: Screen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>3</td>\n",
       "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>1</td>\n",
       "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>8</td>\n",
       "      <td>From: gunning@cco.caltech.edu (Kevin J. Gunnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       intent                                             phrase\n",
       "11309      13  From: jim.zisfein@factory.com (Jim Zisfein) \\n...\n",
       "11310       4  From: ebodin@pearl.tufts.edu\\nSubject: Screen ...\n",
       "11311       3  From: westes@netcom.com (Will Estes)\\nSubject:...\n",
       "11312       1  From: steve@hcrlgw (Steven Collins)\\nSubject: ...\n",
       "11313       8  From: gunning@cco.caltech.edu (Kevin J. Gunnin..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>14</td>\n",
       "      <td>From: richmond@spiff.Princeton.EDU (Stupendous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7528</th>\n",
       "      <td>4</td>\n",
       "      <td>From: smytonj@murr11.alleg.edu (Jim Smyton)\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>9</td>\n",
       "      <td>From: hhenderson@vax.clarku.edu\\nSubject: RE: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>6</td>\n",
       "      <td>From: b859zam@utarlg.uta.edu \\nSubject: INTEL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>15</td>\n",
       "      <td>From: adamsj@gtewd.mtv.gtegsc.com\\nSubject: Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      intent                                             phrase\n",
       "7527      14  From: richmond@spiff.Princeton.EDU (Stupendous...\n",
       "7528       4  From: smytonj@murr11.alleg.edu (Jim Smyton)\\nS...\n",
       "7529       9  From: hhenderson@vax.clarku.edu\\nSubject: RE: ...\n",
       "7530       6  From: b859zam@utarlg.uta.edu \\nSubject: INTEL ...\n",
       "7531      15  From: adamsj@gtewd.mtv.gtegsc.com\\nSubject: Re..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pruning training dataset for a given number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [phrase, intent]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_training = pd.DataFrame(columns=['phrase','intent'])\n",
    "pruned_valid = pd.DataFrame(columns=['phrase','intent'])\n",
    "pruned_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL 0\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 380\n",
      "LABEL 1\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 484\n",
      "LABEL 2\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 491\n",
      "LABEL 3\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 490\n",
      "LABEL 4\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 478\n",
      "LABEL 5\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 493\n",
      "LABEL 6\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 485\n",
      "LABEL 7\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 494\n",
      "LABEL 8\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 498\n",
      "LABEL 9\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 497\n",
      "LABEL 10\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 500\n",
      "LABEL 11\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 495\n",
      "LABEL 12\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 491\n",
      "LABEL 13\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 494\n",
      "LABEL 14\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 493\n",
      "LABEL 15\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 499\n",
      "LABEL 16\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 446\n",
      "LABEL 17\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 464\n",
      "LABEL 18\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 365\n",
      "LABEL 19\n",
      " --- # Training_Phrases = 100\n",
      " --- # Validing_Phrases = 277\n"
     ]
    }
   ],
   "source": [
    "pruning_size = 100\n",
    "for i in list(set(train_dataset.intent)):\n",
    "    print(\"LABEL {}\".format(i))\n",
    "    sample_training = train_dataset[train_dataset.intent == i][0:pruning_size]\n",
    "    sample_valid = train_dataset[train_dataset.intent == i][pruning_size:]\n",
    "    print(\" --- # Training_Phrases = {}\".format(len(sample_training)))\n",
    "    print(\" --- # Validing_Phrases = {}\".format(len(sample_valid))) \n",
    "    pruned_training = pd.concat([pruned_training, sample_training]).reset_index(drop=True)\n",
    "    pruned_valid = pd.concat([pruned_valid, sample_valid]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>19</td>\n",
       "      <td>From: royc@rbdc.wsnc.org (Roy Crabtree)\\nSubje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>19</td>\n",
       "      <td>From: bskendig@netcom.com (Brian Kendig)\\nSubj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>19</td>\n",
       "      <td>From: mccullou@snake2.cs.wisc.edu (Mark McCull...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>19</td>\n",
       "      <td>From: kilroy@gboro.rowan.edu (Dr Nancy's Sweet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>19</td>\n",
       "      <td>From: pharvey@quack.kfu.com (Paul Harvey)\\nSub...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     intent                                             phrase\n",
       "1995     19  From: royc@rbdc.wsnc.org (Roy Crabtree)\\nSubje...\n",
       "1996     19  From: bskendig@netcom.com (Brian Kendig)\\nSubj...\n",
       "1997     19  From: mccullou@snake2.cs.wisc.edu (Mark McCull...\n",
       "1998     19  From: kilroy@gboro.rowan.edu (Dr Nancy's Sweet...\n",
       "1999     19  From: pharvey@quack.kfu.com (Paul Harvey)\\nSub..."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_training.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intent</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9309</th>\n",
       "      <td>19</td>\n",
       "      <td>From: system@kalki33.lakes.trenton.sc.us (Kalk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>19</td>\n",
       "      <td>From: clavazzi@nyx.cs.du.edu (The_Doge)\\nSubje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>19</td>\n",
       "      <td>From: hudson@athena.cs.uga.edu (Paul Hudson Jr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9312</th>\n",
       "      <td>19</td>\n",
       "      <td>From: jmeritt@mental.MITRE.ORG (Jim Meritt - S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9313</th>\n",
       "      <td>19</td>\n",
       "      <td>From: Pegasus@aaa.uoregon.edu (Pegasus)\\nSubje...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     intent                                             phrase\n",
       "9309     19  From: system@kalki33.lakes.trenton.sc.us (Kalk...\n",
       "9310     19  From: clavazzi@nyx.cs.du.edu (The_Doge)\\nSubje...\n",
       "9311     19  From: hudson@athena.cs.uga.edu (Paul Hudson Jr...\n",
       "9312     19  From: jmeritt@mental.MITRE.ORG (Jim Meritt - S...\n",
       "9313     19  From: Pegasus@aaa.uoregon.edu (Pegasus)\\nSubje..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_valid.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean Dataset (only stopword removal, punct, ascii - no lemma, stemm)\n",
    "pruned_training['clean_text']=pruned_training['phrase'].apply(lambda x: transformText(x))\n",
    "pruned_valid['clean_text']=pruned_valid['phrase'].apply(lambda x: transformText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: mathew <mathew@mantis.co.uk>\\nSubject: Re: <Political Atheists?\\nOrganization: Mantis Consultants, Cambridge. UK.\\nX-Newsreader: rusnews v1.01\\nLines: 22\\n\\nkmr4@po.CWRU.edu (Keith M. Ryan) writes:\\n> ( I am almost sure that Zyklon-B is immediate and painless method of \\n> death. If not, insert soem other form. )\\n> \\n>         And, ethnic and minority groups have been killed, mutilated and \\n> exterminated through out history, so I guess it was not unusual.\\n> \\n>         So, you would agree that the holocost would be allowed under the US \\n> Constitution?  [ in so far, the punishment. I doubt they recieved what would \\n> be considered a \"fair\" trial by US standards.\\n\\nDon\\'t be so sure.  Look what happened to Japanese citizens in the US during\\nWorld War II.  If you\\'re prepared to say \"Let\\'s round these people up and\\nstick them in a concentration camp without trial\", it\\'s only a short step to\\ngassing them without trial.  After all, it seems that the Nazis originally\\nonly intended to imprison the Jews; the Final Solution was dreamt up partly\\nbecause they couldn\\'t afford to run the camps because of the devastation\\ncaused by Goering\\'s Total War.  Those who weren\\'t gassed generally died of\\nmalnutrition or disease.\\n\\n\\nmathew\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_training.phrase[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from mathew subject re political atheists organization mantis consultants cambridge uk x newsreader rusnews v1 01 lines 22 keith m ryan writes almost sure zyklon b immediate painless method death not insert soem form and ethnic minority groups killed mutilated exterminated history guess unusual so would agree holocost would allowed us constitution far punishment doubt recieved would considered fair trial us standards sure look happened japanese citizens us world war ii prepared say let s round people stick concentration camp without trial short step gassing without trial all seems nazis originally intended imprison jews final solution dreamt partly afford run camps devastation caused goering s total war gassed generally died malnutrition disease mathew'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_training.clean_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: healta@saturn.wwc.edu (Tammy R Healy)\\nSubject: Re: who are we to judge, Bobby?\\nLines: 38\\nOrganization: Walla Walla College\\nLines: 38\\n\\nIn article <1993Apr14.213356.22176@ultb.isc.rit.edu> snm6394@ultb.isc.rit.edu (S.N. Mozumder ) writes:\\n>From: snm6394@ultb.isc.rit.edu (S.N. Mozumder )\\n>Subject: Re: who are we to judge, Bobby?\\n>Date: Wed, 14 Apr 1993 21:33:56 GMT\\n>In article <healta.56.734556346@saturn.wwc.edu> healta@saturn.wwc.edu (TAMMY R HEALY) writes:\\n>>Bobby,\\n>>\\n>>I would like to take the liberty to quote from a Christian writer named \\n>>Ellen G. White.  I hope that what she said will help you to edit your \\n>>remarks in this group in the future.\\n>>\\n>>\"Do not set yourself as a standard.  Do not make your opinions, your views \\n>>of duty, your interpretations of scripture, a criterion for others and in \\n>>your heart condemn them if they do not come up to your ideal.\"\\n>>                         Thoughts Fromthe Mount of Blessing p. 124\\n>>\\n>>I hope quoting this doesn\\'t make the atheists gag, but I think Ellen White \\n>>put it better than I could.\\n>> \\n>>Tammy\\n>\\n>Point?\\n>\\n>Peace,\\n>\\n>Bobby Mozumder\\n>\\nMy point is that you set up your views as the only way to believe.  Saying \\nthat all eveil in this world is caused by atheism is ridiculous and \\ncounterproductive to dialogue in this newsgroups.  I see in your posts a \\nspirit of condemnation of the atheists in this newsgroup bacause they don\\'\\nt believe exactly as you do.  If you\\'re here to try to convert the atheists \\nhere, you\\'re failing miserably.  Who wants to be in position of constantly \\ndefending themselves agaist insulting attacks, like you seem to like to do?!\\nI\\'m sorry you\\'re so blind that you didn\\'t get the messgae in the quote, \\neveryone else has seemed to.\\n\\nTammy\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_valid.phrase[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from tammy r healy subject re judge bobby lines 38 organization walla walla college lines 38 article s n mozumder writes from s n mozumder subject re judge bobby date wed 14 apr 1993 21 33 56 gmt in article tammy r healy writes bobby i would like take liberty quote christian writer named ellen g white hope said help edit remarks group future do set standard make opinions views of duty interpretations scripture criterion others your heart condemn come ideal thoughts fromthe mount blessing p 124 i hope quoting make atheists gag think ellen white put better could tammy point peace bobby mozumder point set views way believe saying eveil world caused atheism ridiculous counterproductive dialogue newsgroups see posts spirit condemnation atheists newsgroup bacause don believe exactly do try convert atheists here failing miserably wants position constantly defending agaist insulting attacks like seem like do i m sorry blind get messgae quote everyone else seemed to tammy'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_valid.clean_text[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/06/2019 17:12:02 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    }
   ],
   "source": [
    "## ELMo\n",
    "#elmo_weights_key_path = '../../vectors/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
    "#elmo_config_key_path = '../../vectors/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'\n",
    "\n",
    "## S3 Configs for SageMaker\n",
    "bucket = 'adp-e-ml-notebooks-sagemaker'             \n",
    "prefix = 'vectors'   \n",
    "elmo_weights_key = '{}/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'.format(prefix)\n",
    "elmo_weights_key_path = os.path.join('s3://', bucket, elmo_weights_key)\n",
    "elmo_config_key = '{}/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'.format(prefix)\n",
    "elmo_config_key_path = os.path.join('s3://', bucket, elmo_config_key)\n",
    "\n",
    "### Elmo Instance\n",
    "elmo = Elmo(elmo_config_key_path, \n",
    "            elmo_weights_key_path, \n",
    "            num_output_representations = 1, \n",
    "            dropout=0.3,\n",
    "            requires_grad = False)\n",
    "if torch.cuda.is_available():\n",
    "    elmo = elmo.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo(sent):\n",
    "    elmo.eval()\n",
    "    sent = [sent.split()]\n",
    "    character_ids = batch_to_ids(sent)\n",
    "    if torch.cuda.is_available():\n",
    "        character_ids = character_ids.cuda()\n",
    "    embeddings = elmo(character_ids)\n",
    "    rep = embeddings['elmo_representations'][0]\n",
    "    rep = rep.squeeze(dim=0)\n",
    "    avg = rep.mean(dim=0)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3639,  0.1719,  0.0151,  ...,  0.5625, -0.5524, -0.0254],\n",
       "       device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_elmo(\"testing this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9314)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pruned_training), len(pruned_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loading Class\n",
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        phrase = self.data.clean_text[index]\n",
    "        X = get_elmo(phrase)\n",
    "        y = self.data.intent[index]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Intents(pruned_training)\n",
    "valid_set = Intents(pruned_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9314)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__len__(), valid_set.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2079, -0.0499,  0.0184,  ...,  0.0531, -0.0010, -0.1197],\n",
       "        device='cuda:0', grad_fn=<MeanBackward0>), 0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2893, -0.0725,  0.1083,  ..., -0.0051, -0.0633, -0.0463],\n",
       "        device='cuda:0', grad_fn=<MeanBackward0>), 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set.__getitem__(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, inputdim, \n",
    "                        nclasses, \n",
    "                        nhidden, \n",
    "                        dropout = 0):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        -dropout:    dropout for MLP\n",
    "        \"\"\"\n",
    "        \n",
    "        self.inputdim = inputdim\n",
    "        self.hidden_dim = nhidden\n",
    "        self.dropout = dropout\n",
    "        self.nclasses = nclasses\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.inputdim, nhidden),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, self.nclasses),\n",
    "            )\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.cuda()\n",
    "    def forward(self, x):\n",
    "        log_probs = self.model(x)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newsgroups_train.target_names), len(newsgroups_test.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIM = elmo.get_output_dim()\n",
    "NUM_LABELS = len(newsgroups_train.target_names)\n",
    "NHIDDEN = 64\n",
    "DROPOUT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMLP(inputdim = INP_DIM ,\n",
    "              nhidden = NHIDDEN,\n",
    "              nclasses = NUM_LABELS,\n",
    "              dropout = DROPOUT)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = model.to(device)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "train_loader = DataLoader(train_set, **params)\n",
    "valid_loader = DataLoader(valid_set, **params)\n",
    "# Hyperparams\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001 \n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "LOSS: 3.0083396434783936. VALID ACCURACY: 6.098346575048314%\n",
      "EPOCH -- 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid 23757) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2962\u001b[0m                 \u001b[0;31m#rprint('Running code', repr(code_obj)) # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2963\u001b[0;31m                 \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_global_ns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2964\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-8ebec5405f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-3da8bc166971>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_elmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-d5310bdb0cc6>\u001b[0m in \u001b[0;36mget_elmo\u001b[0;34m(sent)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcharacter_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcharacter_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'elmo_representations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# run the biLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mbilm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreshaped_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshaped_word_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'activations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_embedding'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mlstm_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_representation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/allennlp/modules/elmo_lstm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mstacked_sequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestoration_indices\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_and_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lstm_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/allennlp/modules/encoder_base.py\u001b[0m in \u001b[0;36msort_and_run_forward\u001b[0;34m(self, module, inputs, mask, hidden_state)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Actually call the module on the sorted PackedSequence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mmodule_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_sequence_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/allennlp/modules/elmo_lstm.py\u001b[0m in \u001b[0;36m_lstm_forward\u001b[0;34m(self, inputs, initial_state)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                                                    \u001b[0mbatch_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                                                    forward_state)\n\u001b[0m\u001b[1;32m    218\u001b[0m             backward_output_sequence, backward_state = backward_layer(backward_output_sequence,\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/allennlp/modules/lstm_cell_with_projection.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, batch_lengths, initial_state)\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# Shape (batch_size, hidden_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mprevious_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_batch_previous_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_length_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;31m# Shape (batch_size, input_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1862\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1863\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1864\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[0;34m(self, code_obj, result)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1864\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 1866\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   1867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1868\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1373\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1281\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1282\u001b[0m             )\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1133\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1078\u001b[0;31m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0mformatted_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_records\u001b[0;34m(self, records, last_unique, recursion_repeat)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlast_unique\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;31m#print '*** record:',file,lnum,func,lines,index  # dbg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m             \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_record\u001b[0;34m(self, frame, file, lnum, func, lines, index)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mname_cont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinereader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m                 \u001b[0;31m# build composite names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtoken_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNAME\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/tokenize.py\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(readline, encoding)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m             \u001b[0mpseudomatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPseudoToken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpseudomatch\u001b[0m\u001b[0;34m:\u001b[0m                                \u001b[0;31m# scan for tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpseudomatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36mhandler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# Python can still get and update the process status successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0m_error_if_any_worker_fails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprevious_handler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0mprevious_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 23757) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace."
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(train_loader):\n",
    "        \n",
    "        ## Step 1 - Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            sent = sent.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        ## Step 2 - Run forward pass\n",
    "        output = model.forward(sent)\n",
    "        \n",
    "        ## Step 3 - Compute loss\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        ## Step 4 = Update parameters\n",
    "        optimizer.step()\n",
    "        if i%50 == 0:\n",
    "            \n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for sent, label in valid_loader:      \n",
    "                if torch.cuda.is_available():\n",
    "                    sent = sent.cuda()\n",
    "                    label = label.cuda()\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                output = model.forward(sent)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += label.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            # Print Loss\n",
    "            print('LOSS: {}. VALID ACCURACY: {}%'.format(loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(phrase):\n",
    "    x = get_elmo(phrase)\n",
    "    logits_out = model.forward(x)\n",
    "    softmax_out = F.softmax(logits_out, dim=0).cpu()\n",
    "    _, pred_label = torch.max(softmax_out.data, 0)\n",
    "    prediction=list(label_to_ix.keys())[pred_label]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reply(\"change this music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reply(\"weather in Porto Alegre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "errors = []\n",
    "accuracy = 0\n",
    "for i in range(len(test_dataset)):\n",
    "    msg = str(test_dataset['clean_text'][i])\n",
    "    lbl = str(test_dataset['intent'][i])\n",
    "    pred = get_reply(msg)\n",
    "    total +=1\n",
    "    if pred == lbl:\n",
    "        correct += 1\n",
    "    else:\n",
    "        errors.append((msg,lbl))\n",
    "test_accuracy = 100.00 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TEST ACCURACY  -- {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (recsys)",
   "language": "python",
   "name": "recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
