{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch, Sklearn imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 1.0.1\n",
      "AllenNLP: 0.8.1\n"
     ]
    }
   ],
   "source": [
    "## AllenNLP\n",
    "import allennlp\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from allennlp.modules.token_embedders import BertEmbedder\n",
    "\n",
    "print(\"PyTorch: {}\".format(torch.__version__))\n",
    "print(\"AllenNLP: {}\".format(allennlp.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/05/2019 23:17:24 - INFO - gensim.summarization.textcleaner -   'pattern' package not found; tag filters are not available for English\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/roberto/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "## NLP libs\n",
    "from nltk import download\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "download('stopwords')\n",
    "\n",
    "## General libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import os, re, sys, json, requests, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/snips_sliced_train.pkl\",'rb') as f:\n",
    "    train_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>Let me listen to an eighties ep.</td>\n",
       "      <td>PlayMusic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Play Les Lecter Smith from deezer.</td>\n",
       "      <td>PlayMusic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>I want to hear Merry Go Round by Gary Nichols ...</td>\n",
       "      <td>PlayMusic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>Please help me find the Bloom: Remix Album song.</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>I would like to hear something from Groove Shark</td>\n",
       "      <td>PlayMusic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                phrase              intent\n",
       "695                   Let me listen to an eighties ep.           PlayMusic\n",
       "696                 Play Les Lecter Smith from deezer.           PlayMusic\n",
       "697  I want to hear Merry Go Round by Gary Nichols ...           PlayMusic\n",
       "698   Please help me find the Bloom: Remix Album song.  SearchCreativeWork\n",
       "699   I would like to hear something from Groove Shark           PlayMusic"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/snips_sliced_test.pkl\",'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>Find the creative work Brilliant! Tragic!</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>Rate the current album a 5 out of 6</td>\n",
       "      <td>RateBook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Please search the Karobar Economic Daily picture.</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>Please find me the Youth Against Fascism telev...</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>add Our Favorite Things to Reggae BBQ playlist</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase              intent\n",
       "1394          Find the creative work Brilliant! Tragic!  SearchCreativeWork\n",
       "1395                Rate the current album a 5 out of 6            RateBook\n",
       "1396  Please search the Karobar Economic Daily picture.  SearchCreativeWork\n",
       "1397  Please find me the Youth Against Fascism telev...  SearchCreativeWork\n",
       "1398     add Our Favorite Things to Reggae BBQ playlist       AddToPlaylist"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatization function based on Spacy Library\n",
    "def lemmatizer_spacy(text):        \n",
    "    sent = []\n",
    "    doc = spacy_en(text)\n",
    "    for word in doc:\n",
    "        if word.lemma_ == \"-PRON-\":\n",
    "            sent.append(word.text)\n",
    "        else:\n",
    "            sent.append(word.lemma_)\n",
    "    return \" \".join(sent)\n",
    "\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text, do_stop=True, do_stem=False, do_lema = False):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    if (do_stop==True):\n",
    "        filtered_words = [word for word in text.split() if word not in stops]\n",
    "    else:\n",
    "        filtered_words = [word for word in text.split()]\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Stemming\n",
    "    if (do_stem==True):\n",
    "        text = gensim.parsing.preprocessing.stem_text(text)\n",
    "    \n",
    "    # Lemmatization\n",
    "    if (do_lema==True):\n",
    "        text = do_lemmatization(text)        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean Dataset (only stopword removal, punct, ascii - no lemma, stemm)\n",
    "train_dataset['clean_text']=train_dataset['phrase'].apply(lambda x: transformText(x))\n",
    "test_dataset['clean_text']=test_dataset['phrase'].apply(lambda x: transformText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>intent</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>Find the creative work Brilliant! Tragic!</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>find creative work brilliant  tragic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>Rate the current album a 5 out of 6</td>\n",
       "      <td>RateBook</td>\n",
       "      <td>rate current album 5 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Please search the Karobar Economic Daily picture.</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>please search karobar economic daily picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>Please find me the Youth Against Fascism telev...</td>\n",
       "      <td>SearchCreativeWork</td>\n",
       "      <td>please find youth fascism television show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>add Our Favorite Things to Reggae BBQ playlist</td>\n",
       "      <td>AddToPlaylist</td>\n",
       "      <td>add favorite things reggae bbq playlist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 phrase              intent  \\\n",
       "1394          Find the creative work Brilliant! Tragic!  SearchCreativeWork   \n",
       "1395                Rate the current album a 5 out of 6            RateBook   \n",
       "1396  Please search the Karobar Economic Daily picture.  SearchCreativeWork   \n",
       "1397  Please find me the Youth Against Fascism telev...  SearchCreativeWork   \n",
       "1398     add Our Favorite Things to Reggae BBQ playlist       AddToPlaylist   \n",
       "\n",
       "                                         clean_text  \n",
       "1394          find creative work brilliant  tragic   \n",
       "1395                         rate current album 5 6  \n",
       "1396  please search karobar economic daily picture   \n",
       "1397     please find youth fascism television show   \n",
       "1398        add favorite things reggae bbq playlist  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict Size: 1507\n",
      "Num labels: 7\n"
     ]
    }
   ],
   "source": [
    "## Build word vocabulary\n",
    "word_to_ix = {}\n",
    "for sent in train_dataset.clean_text:\n",
    "    for word in sent.split():\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "print(\"Dict Size: {}\".format(len(word_to_ix)))\n",
    "## Build label vocabulary\n",
    "label_to_ix = {}\n",
    "for label in train_dataset.intent:\n",
    "    for word in label.split():\n",
    "        if word not in label_to_ix:\n",
    "            label_to_ix[word]=len(label_to_ix)\n",
    "print(\"Num labels: {}\".format(len(label_to_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02/05/2019 23:17:30 - INFO - allennlp.modules.elmo -   Initializing ELMo\n"
     ]
    }
   ],
   "source": [
    "## ELMo\n",
    "elmo_weights_key_path = '../vectors/elmo_2x4096_512_2048cnn_2xhighway_5.5B_weights.hdf5'\n",
    "elmo_config_key_path = '../vectors/elmo_2x4096_512_2048cnn_2xhighway_5.5B_options.json'\n",
    "\n",
    "### Elmo Instance\n",
    "elmo = Elmo(elmo_config_key_path, \n",
    "            elmo_weights_key_path, \n",
    "            num_output_representations = 1, \n",
    "            dropout=0.3,\n",
    "            requires_grad = False)\n",
    "if torch.cuda.is_available():\n",
    "    elmo = elmo.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elmo(sent):\n",
    "    elmo.eval()\n",
    "    sent = [sent.split()]\n",
    "    character_ids = batch_to_ids(sent)\n",
    "    if torch.cuda.is_available():\n",
    "        character_ids = character_ids.cuda()\n",
    "    embeddings = elmo(character_ids)\n",
    "    rep = embeddings['elmo_representations'][0]\n",
    "    rep = rep.squeeze(dim=0)\n",
    "    avg = rep.mean(dim=0)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3639,  0.1719,  0.0151,  ...,  0.5625, -0.5524, -0.0254],\n",
       "       device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_elmo(\"testing this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train/Valid split\n",
    "data_split = int(0.8*len(train_dataset))\n",
    "train = train_dataset[:data_split]\n",
    "valid = train_dataset[data_split:-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 139)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loading Class\n",
    "class Intents(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.len = len(dataframe)\n",
    "        self.label_to_ix = {}\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        phrase = self.data.clean_text[index]\n",
    "        X = get_elmo(phrase)\n",
    "        y = label_to_ix[self.data.intent[index]]\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Intents(train)\n",
    "valid_set = Intents(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 139)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__len__(), valid_set.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2548,  0.1129,  0.0467,  ...,  0.0675,  0.0513, -0.0927],\n",
       "        device='cuda:0', grad_fn=<MeanBackward0>), 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.2492, -0.2486,  0.2828,  ...,  0.1495, -0.0282,  0.0356],\n",
       "        device='cuda:0', grad_fn=<MeanBackward0>), 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_set.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, inputdim, \n",
    "                        nclasses, \n",
    "                        nhidden, \n",
    "                        dropout = 0):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        -dropout:    dropout for MLP\n",
    "        \"\"\"\n",
    "        \n",
    "        self.inputdim = inputdim\n",
    "        self.hidden_dim = nhidden\n",
    "        self.dropout = dropout\n",
    "        self.nclasses = nclasses\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.inputdim, nhidden),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, self.nclasses),\n",
    "            )\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.cuda()\n",
    "    def forward(self, x):\n",
    "        log_probs = self.model(x)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIM = elmo.get_output_dim()\n",
    "NUM_LABELS = len(label_to_ix)\n",
    "NHIDDEN = 32\n",
    "DROPOUT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleMLP(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=32, bias=True)\n",
       "    (1): Dropout(p=0)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=32, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SimpleMLP(inputdim = INP_DIM ,\n",
    "              nhidden = NHIDDEN,\n",
    "              nclasses = NUM_LABELS,\n",
    "              dropout = DROPOUT)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = model.to(device)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders Parameters\n",
    "params = {'batch_size': 32,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "train_loader = DataLoader(train_set, **params)\n",
    "valid_loader = DataLoader(valid_set, **params)\n",
    "# Hyperparams\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001 \n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "LOSS: 1.9605387449264526. VALID ACCURACY: 20.14388489208633%\n",
      "EPOCH -- 1\n",
      "LOSS: 1.4189391136169434. VALID ACCURACY: 71.94244604316546%\n",
      "EPOCH -- 2\n",
      "LOSS: 0.7784044146537781. VALID ACCURACY: 82.73381294964028%\n",
      "EPOCH -- 3\n",
      "LOSS: 0.6431792974472046. VALID ACCURACY: 89.92805755395683%\n",
      "EPOCH -- 4\n",
      "LOSS: 0.535935640335083. VALID ACCURACY: 92.0863309352518%\n",
      "EPOCH -- 5\n",
      "LOSS: 0.26855212450027466. VALID ACCURACY: 93.5251798561151%\n",
      "EPOCH -- 6\n",
      "LOSS: 0.2044243961572647. VALID ACCURACY: 93.5251798561151%\n",
      "EPOCH -- 7\n",
      "LOSS: 0.1212158277630806. VALID ACCURACY: 94.24460431654676%\n",
      "EPOCH -- 8\n",
      "LOSS: 0.19033342599868774. VALID ACCURACY: 94.24460431654676%\n",
      "EPOCH -- 9\n",
      "LOSS: 0.11237333714962006. VALID ACCURACY: 94.96402877697842%\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 10\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(train_loader):\n",
    "        \n",
    "        ## Step 1 - Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            sent = sent.cuda()\n",
    "            label = label.cuda()\n",
    "        \n",
    "        ## Step 2 - Run forward pass\n",
    "        output = model.forward(sent)\n",
    "        \n",
    "        ## Step 3 - Compute loss\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        \n",
    "        ## Step 4 = Update parameters\n",
    "        optimizer.step()\n",
    "        if i%50 == 0:\n",
    "            \n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            \n",
    "            for sent, label in valid_loader:      \n",
    "                if torch.cuda.is_available():\n",
    "                    sent = sent.cuda()\n",
    "                    label = label.cuda()\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                output = model.forward(sent)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += label.size(0)\n",
    "\n",
    "                # Total correct predictions\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            # Print Loss\n",
    "            print('LOSS: {}. VALID ACCURACY: {}%'.format(loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reply(phrase):\n",
    "    x = get_elmo(phrase)\n",
    "    logits_out = model.forward(x)\n",
    "    softmax_out = F.softmax(logits_out, dim=0).cpu()\n",
    "    _, pred_label = torch.max(softmax_out.data, 0)\n",
    "    prediction=list(label_to_ix.keys())[pred_label]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PlayMusic'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"change this music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GetWeather'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_reply(\"weather in Porto Alegre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "errors = []\n",
    "accuracy = 0\n",
    "for i in range(len(test_dataset)):\n",
    "    msg = str(test_dataset['clean_text'][i])\n",
    "    lbl = str(test_dataset['intent'][i])\n",
    "    pred = get_reply(msg)\n",
    "    total +=1\n",
    "    if pred == lbl:\n",
    "        correct += 1\n",
    "    else:\n",
    "        errors.append((msg,lbl))\n",
    "test_accuracy = 100.00 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY  -- 96.85489635453895\n"
     ]
    }
   ],
   "source": [
    "print(\"TEST ACCURACY  -- {}\".format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
