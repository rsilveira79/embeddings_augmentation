{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch, Sklearn imports\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 1.0.0.dev20190206\n",
      "AllenNLP: 0.8.1\n",
      "Using CUDA device: 0\n",
      "- # GPU device: 1\n",
      "- Device Name: GeForce GTX 1080 Ti\n",
      "- Device Proprierties: _CudaDeviceProperties(name='GeForce GTX 1080 Ti', major=6, minor=1, total_memory=11175MB, multi_processor_count=28)\n"
     ]
    }
   ],
   "source": [
    "# AllenNLP\n",
    "import allennlp\n",
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
    "from allennlp.modules.token_embedders import BertEmbedder\n",
    "\n",
    "print(\"PyTorch: {}\".format(torch.__version__))\n",
    "print(\"AllenNLP: {}\".format(allennlp.__version__))\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print(\"Using CUDA device: {}\".format(device))\n",
    "    print(\"- # GPU device: {}\".format(torch.cuda.device_count()))\n",
    "    print(\"- Device Name: {}\".format(torch.cuda.get_device_name(device)))\n",
    "    print(\"- Device Proprierties: {}\".format(torch.cuda.get_device_properties(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "import os, re, sys, json, requests, pickle\n",
    "\n",
    "## Sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/train_elmos.pkl\",\"rb\") as f:\n",
    "    train_elmos, train_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/test_elmos.pkl\",\"rb\") as f:\n",
    "    test_elmos, test_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68916, 1024), (68916,), (2140, 1024), (2140,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_elmos.shape, train_labels.shape, test_elmos.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55132, 1024), (55132,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(train_elmos, train_labels, test_size=0.20, random_state=42)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentsPrecomp(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.len = len(X)\n",
    "        self.data = X\n",
    "        self.label = Y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        X = torch.tensor(self.data[index], dtype=torch.float32)\n",
    "        y = torch.tensor(self.label[index], dtype=torch.int64)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = IntentsPrecomp(x_train, y_train)\n",
    "validing_set = IntentsPrecomp(x_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, inputdim, \n",
    "                        nclasses, \n",
    "                        nhidden, \n",
    "                        dropout = 0):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        \"\"\"\n",
    "        PARAMETERS:\n",
    "        -dropout:    dropout for MLP\n",
    "        \"\"\"\n",
    "        \n",
    "        self.inputdim = inputdim\n",
    "        self.hidden_dim = nhidden\n",
    "        self.dropout = dropout\n",
    "        self.nclasses = nclasses\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.inputdim, nhidden),\n",
    "            nn.Dropout(p=self.dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, self.nclasses),\n",
    "            )\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.cuda()\n",
    "    def forward(self, x):\n",
    "        log_probs = self.model(x)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIM = train_elmos.shape[1]\n",
    "NUM_LABELS = len((set(test_labels)))\n",
    "NHIDDEN = 2048\n",
    "DROPOUT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleMLP(inputdim = INP_DIM ,\n",
    "              nhidden = NHIDDEN,\n",
    "              nclasses = NUM_LABELS,\n",
    "              dropout = DROPOUT)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    model = model.to(device)\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0058,  0.0202,  0.0230,  0.0220, -0.0164], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = training_set.__getitem__(0)[0].cuda()\n",
    "model.forward(samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders Parameters\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "max_epochs = 30\n",
    "\n",
    "train_loader = DataLoader(training_set, **params)\n",
    "valid_loader = DataLoader(validing_set, **params)\n",
    "# Hyperparams\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.0001 \n",
    "optimizer = optim.Adam(params =  model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH -- 0\n",
      "LOSS: 1.6059281826019287. VALID ACCURACY: 28.605629715612306%\n",
      "EPOCH -- 1\n",
      "LOSS: 1.1538652181625366. VALID ACCURACY: 50.68195008705746%\n",
      "EPOCH -- 2\n",
      "LOSS: 1.1874431371688843. VALID ACCURACY: 53.1485780615206%\n",
      "EPOCH -- 3\n",
      "LOSS: 1.083764910697937. VALID ACCURACY: 53.525827045850264%\n",
      "EPOCH -- 4\n",
      "LOSS: 0.9412069320678711. VALID ACCURACY: 54.432675565873474%\n",
      "EPOCH -- 5\n",
      "LOSS: 0.9073969721794128. VALID ACCURACY: 54.4181659895531%\n",
      "EPOCH -- 6\n",
      "LOSS: 1.0376415252685547. VALID ACCURACY: 54.62130005803831%\n",
      "EPOCH -- 7\n",
      "LOSS: 1.0445117950439453. VALID ACCURACY: 54.904236796285545%\n",
      "EPOCH -- 8\n",
      "LOSS: 1.0572164058685303. VALID ACCURACY: 55.383052814857805%\n",
      "EPOCH -- 9\n",
      "LOSS: 1.002320408821106. VALID ACCURACY: 55.390307603017995%\n",
      "EPOCH -- 10\n",
      "LOSS: 1.0465998649597168. VALID ACCURACY: 55.46285548461985%\n",
      "EPOCH -- 11\n",
      "LOSS: 1.1100976467132568. VALID ACCURACY: 55.724027858386535%\n",
      "EPOCH -- 12\n",
      "LOSS: 0.8420049548149109. VALID ACCURACY: 55.62971561230412%\n",
      "EPOCH -- 13\n",
      "LOSS: 0.8491542935371399. VALID ACCURACY: 56.079512478235635%\n",
      "EPOCH -- 14\n",
      "LOSS: 0.929384171962738. VALID ACCURACY: 56.13755078351712%\n",
      "EPOCH -- 15\n",
      "LOSS: 0.8683458566665649. VALID ACCURACY: 56.32617527568195%\n",
      "EPOCH -- 16\n",
      "LOSS: 0.8438997268676758. VALID ACCURACY: 56.68891468369124%\n",
      "EPOCH -- 17\n",
      "LOSS: 1.0092850923538208. VALID ACCURACY: 56.84126523505514%\n",
      "EPOCH -- 18\n",
      "LOSS: 0.9580788016319275. VALID ACCURACY: 56.84852002321532%\n",
      "EPOCH -- 19\n",
      "LOSS: 0.936242401599884. VALID ACCURACY: 57.12420197330238%\n",
      "EPOCH -- 20\n",
      "LOSS: 0.9676626920700073. VALID ACCURACY: 57.247533372025536%\n",
      "EPOCH -- 21\n",
      "LOSS: 0.8463761806488037. VALID ACCURACY: 57.66831108531631%\n",
      "EPOCH -- 22\n",
      "LOSS: 0.8084267377853394. VALID ACCURACY: 57.71909460243761%\n",
      "EPOCH -- 23\n",
      "LOSS: 0.806303083896637. VALID ACCURACY: 57.9802669762043%\n",
      "EPOCH -- 24\n",
      "LOSS: 0.78177809715271. VALID ACCURACY: 57.914973882762624%\n",
      "EPOCH -- 25\n",
      "LOSS: 0.8427096605300903. VALID ACCURACY: 57.76262333139872%\n",
      "EPOCH -- 26\n",
      "LOSS: 0.8080382347106934. VALID ACCURACY: 57.74085896691817%\n",
      "EPOCH -- 27\n",
      "LOSS: 0.902752697467804. VALID ACCURACY: 58.13261752756819%\n",
      "EPOCH -- 28\n",
      "LOSS: 0.7013740539550781. VALID ACCURACY: 58.386535113174695%\n",
      "EPOCH -- 29\n",
      "LOSS: 0.7612961530685425. VALID ACCURACY: 58.502611723737665%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print(\"EPOCH -- {}\".format(epoch))\n",
    "    for i, (sent, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad() \n",
    "        if torch.cuda.is_available():\n",
    "            sent = sent.cuda()\n",
    "            label = label.cuda()\n",
    "        output = model.forward(sent)\n",
    "        loss = loss_function(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i%1000 == 0:      \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for sent, label in valid_loader:      \n",
    "                if torch.cuda.is_available():\n",
    "                    sent = sent.cuda()\n",
    "                    label = label.cuda()\n",
    "                output = model.forward(sent)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += label.size(0)\n",
    "                correct += (predicted.cpu() == label.cpu()).sum()\n",
    "            accuracy = 100.00 * correct.numpy() / total\n",
    "            print('LOSS: {}. VALID ACCURACY: {}%'.format(loss.data, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST ACCURACY  -- 46.02803738317757\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for i, utt in enumerate(test_elmos):\n",
    "    X = torch.tensor(utt, dtype=torch.float32).cuda()\n",
    "    y = torch.tensor(test_labels[i], dtype=torch.int64)\n",
    "    logits_out = model(X)\n",
    "    softmax_out = F.softmax(logits_out, dim=0).cpu()\n",
    "    _, pred_label = torch.max(softmax_out.data, 0)\n",
    "    total +=1\n",
    "    if pred_label == y:\n",
    "        correct += 1\n",
    "test_accuracy = 100.00 * correct / total\n",
    "print(\"TEST ACCURACY  -- {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Augmentation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from torch.nn.functional import interpolate\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_interpolation(label, num_interp_samples, return_all_points=False):\n",
    "    sentences= list(train_pruned.clean_text[train_dataset.label == label])\n",
    "    points = np.zeros((elmo.get_output_dim(),len(sentences)))    \n",
    "    \n",
    "    for i,utt in enumerate(sentences):\n",
    "        points[:,i] = get_elmo(utt).detach().cpu().clone().numpy()\n",
    "    point = torch.tensor(points)\n",
    "    x = point.unsqueeze(dim=0) \n",
    "    \n",
    "    ## Random selector for which interpolated phrase to pick\n",
    "    rand_phrase = np.random.randint(num_interp_samples, size = 1)\n",
    "    \n",
    "    ## Interpolate phrases\n",
    "    interp = interpolate(x, size=(num_interp_samples), mode='linear', align_corners=True).squeeze(0).numpy().T\n",
    "    \n",
    "    if return_all_points == False:\n",
    "        interp =interp[rand_phrase].squeeze(0)      ## Pick Randomly 1 point sample\n",
    "    return interp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
